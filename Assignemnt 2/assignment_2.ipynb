{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e9f2eba6-fa9b-4737-934f-d1b6baf91817",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9f2eba6-fa9b-4737-934f-d1b6baf91817",
        "outputId": "50b41be6-4a4c-4006-d0fe-7fbe93d0b4d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#loading necessary libraries\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "import pandas as pd\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection, naive_bayes, svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "#from collections import defaultdict\n",
        "#from nltk import pos_tag\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ee6e4c4f-d10a-4505-b6dd-049f1e306949",
      "metadata": {
        "id": "ee6e4c4f-d10a-4505-b6dd-049f1e306949"
      },
      "outputs": [],
      "source": [
        "#setting same randomization every time\n",
        "np.random.seed(500)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6ced66a6-3463-40ff-ade9-4513b7470374",
      "metadata": {
        "id": "6ced66a6-3463-40ff-ade9-4513b7470374"
      },
      "outputs": [],
      "source": [
        "init_df=pd.read_csv(\"/content/train main.xls\" , encoding=\"latin-1\", usecols=['category','text'] , delimiter=\",\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "405c1379-a1a3-40ca-a944-781865724a9c",
      "metadata": {
        "id": "405c1379-a1a3-40ca-a944-781865724a9c"
      },
      "outputs": [],
      "source": [
        "#cleaning and tokenizing begins\n",
        "init_df[\"text\"].dropna(inplace=True)\n",
        "init_df['text']=[entry.lower() for entry in init_df['text']]\n",
        "init_df['text']= [word_tokenize(entry) for entry in init_df['text']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "52da3e51-f97d-4714-9ebe-8ccb780ed53c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52da3e51-f97d-4714-9ebe-8ccb780ed53c",
        "outputId": "907f5e92-24ae-4037-bf6e-720088266820"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sport            511\n",
              "business         510\n",
              "politics         417\n",
              "tech             401\n",
              "entertainment    386\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#check if the categoris have nearly same number of texts\n",
        "init_df['category'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "13d29081-8e63-4eb0-a4b4-cae11671dcf5",
      "metadata": {
        "scrolled": true,
        "id": "13d29081-8e63-4eb0-a4b4-cae11671dcf5"
      },
      "outputs": [],
      "source": [
        "lemmatizer= WordNetLemmatizer()\n",
        "Stemmer = PorterStemmer()\n",
        "for index, entry in enumerate(init_df['text']) :\n",
        "    Final_words = []\n",
        "    for word in entry :\n",
        "           if word not in stopwords.words('english') and word.isalpha() :\n",
        "            word_Final = Stemmer.stem(word)\n",
        "            Final_words.append(word_Final)\n",
        "           elif not word.isalpha():\n",
        "                Final_words.append(word)\n",
        "    init_df.loc[index,'cleaned_text']=str(Final_words)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "813039f6-a6e2-41e4-ba38-1d8429850ea1",
      "metadata": {
        "id": "813039f6-a6e2-41e4-ba38-1d8429850ea1"
      },
      "outputs": [],
      "source": [
        "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(init_df['cleaned_text'],init_df['category'],test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "99dd2572-e2d4-49c7-9a7e-84945e806916",
      "metadata": {
        "id": "99dd2572-e2d4-49c7-9a7e-84945e806916"
      },
      "outputs": [],
      "source": [
        "#check if the train dataset's categoris have nearly same number of texts\n",
        "min=Train_Y.value_counts().min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "41e2f886-9010-427f-ad9b-7ac5a69511e0",
      "metadata": {
        "id": "41e2f886-9010-427f-ad9b-7ac5a69511e0"
      },
      "outputs": [],
      "source": [
        "Tfidf_vect = TfidfVectorizer(min_df=4)\n",
        "Tfidf_vect.fit(init_df['cleaned_text'])\n",
        "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
        "Test_X_Tfidf = Tfidf_vect.transform(Test_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "004dd435-81a6-425c-979a-8ec5731cfbfb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "004dd435-81a6-425c-979a-8ec5731cfbfb",
        "outputId": "4df2d483-3279-4966-df96-ead24b3897ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy Score ->  98.42696629213484\n",
            "[[102   0   2   1   0]\n",
            " [  1  76   0   0   0]\n",
            " [  0   1  87   0   0]\n",
            " [  0   0   0  80   1]\n",
            " [  1   0   0   0  93]]\n"
          ]
        }
      ],
      "source": [
        "NB = naive_bayes.MultinomialNB(alpha=1)\n",
        "NB.fit(Train_X_Tfidf,Train_Y)\n",
        "\n",
        "# predict the labels on the test dataset\n",
        "pred_NB = NB.predict(Test_X_Tfidf)\n",
        "\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(pred_NB, Test_Y)*100)\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "confmatrix=confusion_matrix(pred_NB, Test_Y)\n",
        "print (confmatrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e09f457f-15af-46ba-9301-50c1001afe0e",
      "metadata": {
        "id": "e09f457f-15af-46ba-9301-50c1001afe0e"
      },
      "outputs": [],
      "source": [
        "columns = Tfidf_vect.get_feature_names_out()\n",
        "train_tfidf_df = pd.DataFrame(Train_X_Tfidf.toarray(), columns=columns)\n",
        "test_tfidf_df = pd.DataFrame(Test_X_Tfidf.toarray(), columns=columns)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For testing\n",
        "Test_main=pd.read_csv('/content/tester.csv',usecols=['text'])    #enter the path to test dataset containing only texts,making sure its header is apt\n",
        "Test_main['text'].dropna(inplace=True)\n",
        "Test_main['text']=[entry.lower() for entry in Test_main['text']]"
      ],
      "metadata": {
        "id": "E-dBxd7elNu8"
      },
      "id": "E-dBxd7elNu8",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Test_main['tokenized']= [word_tokenize(entry) for entry in Test_main['text']]"
      ],
      "metadata": {
        "id": "2WO-mfG-lQGJ"
      },
      "id": "2WO-mfG-lQGJ",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for index, entry in enumerate(Test_main['tokenized']) :\n",
        "    Final_words = []\n",
        "    for word in entry :\n",
        "           if word not in stopwords.words('english') and word.isalpha() :\n",
        "            word_Final = Stemmer.stem(word)\n",
        "            Final_words.append(word_Final)\n",
        "           elif not word.isalpha():\n",
        "                Final_words.append(word)\n",
        "    Test_main.loc[index,'cleaned_text']=str(Final_words)"
      ],
      "metadata": {
        "id": "UFu64gNNksMF"
      },
      "id": "UFu64gNNksMF",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "caec3043-8ee2-4d3d-b31a-5771ded9f9e7",
      "metadata": {
        "id": "caec3043-8ee2-4d3d-b31a-5771ded9f9e7"
      },
      "outputs": [],
      "source": [
        "Vect=Tfidf_vect.transform(Test_main['cleaned_text'])\n",
        "pred_NB2 = NB.predict(Vect)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b40fd59c-5c08-4326-a66b-49282e9407c8",
      "metadata": {
        "id": "b40fd59c-5c08-4326-a66b-49282e9407c8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}